{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "54bc77d2-8b45-43e2-aaba-fa4583d44d0f",
      "metadata": {
        "id": "54bc77d2-8b45-43e2-aaba-fa4583d44d0f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "956dcabe-dbd5-4367-be08-9aa9e76d7ff1",
      "metadata": {
        "id": "956dcabe-dbd5-4367-be08-9aa9e76d7ff1"
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "137bf32a-5fab-4e02-937e-3dd29ac1de2f",
      "metadata": {
        "id": "137bf32a-5fab-4e02-937e-3dd29ac1de2f"
      },
      "outputs": [],
      "source": [
        "# Load Dataset (MNIST-like)\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "dataset = datasets.MNIST(root=\"data\", train=True, transform=transform, download=True)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "f75e3940-10a7-4257-baae-fd2b3b4642fe",
      "metadata": {
        "id": "f75e3940-10a7-4257-baae-fd2b3b4642fe"
      },
      "outputs": [],
      "source": [
        "latent_dim = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "912d2d4b-ed48-4d92-90ac-9e55f6b72198",
      "metadata": {
        "id": "912d2d4b-ed48-4d92-90ac-9e55f6b72198"
      },
      "outputs": [],
      "source": [
        "# Define VAutoencoder Model\n",
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim=28*28, latent_dim=64):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        # self.encoder = nn.Sequential() Can no longer build with sequential because we have two paths to train. One to mu, the other to sigma^2 (variance)\n",
        "\n",
        "        # Shared encoder\n",
        "        self.encoder_fc1 = nn.Linear(input_dim, 128)\n",
        "\n",
        "        # Separate paths for mean and log variance\n",
        "        self.fc_mu = nn.Linear(128, latent_dim)\n",
        "        self.fc_var = nn.Linear(128, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.decode = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim),\n",
        "            nn.Sigmoid()  # Output in range [0,1] for images\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        hidden_layer = F.relu(self.encoder_fc1(x))\n",
        "        mu = self.fc_mu(hidden_layer)\n",
        "        logvar = self.fc_var(hidden_layer) # actually the log variance\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar) # this is why it's the log variance e^(0.5*var)\n",
        "        eps = torch.randn_like(std) # randomly generated from a standard normal distribution *like* (same dimensions) std\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        decoded = self.decode(z)\n",
        "        return decoded, mu, logvar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "86f2a4d9-bf0e-42c0-a80d-cf4e21dc3e7e",
      "metadata": {
        "id": "86f2a4d9-bf0e-42c0-a80d-cf4e21dc3e7e"
      },
      "outputs": [],
      "source": [
        "def vae_loss(decoded_images, images, mu, logvar):\n",
        "    recon_loss = nn.MSELoss()(decoded_images, images) #\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)\n",
        "    return recon_loss + KLD.mean() # think about what must be returned here for the loss.backward() step to work properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "847a8e95",
      "metadata": {
        "id": "847a8e95"
      },
      "outputs": [],
      "source": [
        "# def vae_loss(decoded_images, images, mu, logvar):\n",
        "#     recon_loss = nn.MSELoss()(decoded_images, images) #\n",
        "#     KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(),dim=1)\n",
        "#     return recon_loss + KLD # think about what must be returned here for the loss.backward() step to work properly."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "CguIC7Fnj39C"
      },
      "id": "CguIC7Fnj39C",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c56b64e-b9c3-4de9-a41b-57c84f9d45fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c56b64e-b9c3-4de9-a41b-57c84f9d45fe",
        "outputId": "60cb7790-d53a-4d74-8d04-0dc5b95bf953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 0.0639\n",
            "Epoch [2/100], Loss: 0.0716\n",
            "Epoch [3/100], Loss: 0.0651\n",
            "Epoch [4/100], Loss: 0.0669\n",
            "Epoch [5/100], Loss: 0.0633\n",
            "Epoch [6/100], Loss: 0.0680\n",
            "Epoch [7/100], Loss: 0.0607\n",
            "Epoch [8/100], Loss: 0.0703\n",
            "Epoch [9/100], Loss: 0.0649\n",
            "Epoch [10/100], Loss: 0.0642\n",
            "Epoch [11/100], Loss: 0.0672\n",
            "Epoch [12/100], Loss: 0.0656\n",
            "Epoch [13/100], Loss: 0.0661\n",
            "Epoch [14/100], Loss: 0.0750\n",
            "Epoch [15/100], Loss: 0.0685\n",
            "Epoch [16/100], Loss: 0.0710\n",
            "Epoch [17/100], Loss: 0.0669\n",
            "Epoch [18/100], Loss: 0.0676\n",
            "Epoch [19/100], Loss: 0.0687\n",
            "Epoch [20/100], Loss: 0.0643\n",
            "Epoch [21/100], Loss: 0.0648\n",
            "Epoch [22/100], Loss: 0.0655\n",
            "Epoch [23/100], Loss: 0.0655\n",
            "Epoch [24/100], Loss: 0.0728\n",
            "Epoch [25/100], Loss: 0.0709\n",
            "Epoch [26/100], Loss: 0.0699\n",
            "Epoch [27/100], Loss: 0.0686\n",
            "Epoch [28/100], Loss: 0.0649\n",
            "Epoch [29/100], Loss: 0.0699\n",
            "Epoch [30/100], Loss: 0.0704\n",
            "Epoch [31/100], Loss: 0.0660\n",
            "Epoch [32/100], Loss: 0.0742\n",
            "Epoch [33/100], Loss: 0.0697\n",
            "Epoch [34/100], Loss: 0.0662\n",
            "Epoch [35/100], Loss: 0.0753\n",
            "Epoch [36/100], Loss: 0.0639\n",
            "Epoch [37/100], Loss: 0.0652\n",
            "Epoch [38/100], Loss: 0.0725\n",
            "Epoch [39/100], Loss: 0.0615\n",
            "Epoch [40/100], Loss: 0.0633\n",
            "Epoch [41/100], Loss: 0.0673\n",
            "Epoch [42/100], Loss: 0.0678\n",
            "Epoch [43/100], Loss: 0.0577\n",
            "Epoch [44/100], Loss: 0.0640\n",
            "Epoch [45/100], Loss: 0.0685\n",
            "Epoch [46/100], Loss: 0.0598\n",
            "Epoch [47/100], Loss: 0.0696\n",
            "Epoch [48/100], Loss: 0.0716\n",
            "Epoch [49/100], Loss: 0.0677\n",
            "Epoch [50/100], Loss: 0.0677\n",
            "Epoch [51/100], Loss: 0.0743\n",
            "Epoch [52/100], Loss: 0.0670\n",
            "Epoch [53/100], Loss: 0.0664\n",
            "Epoch [54/100], Loss: 0.0619\n",
            "Epoch [55/100], Loss: 0.0719\n",
            "Epoch [56/100], Loss: 0.0678\n",
            "Epoch [57/100], Loss: 0.0676\n",
            "Epoch [58/100], Loss: 0.0656\n",
            "Epoch [59/100], Loss: 0.0656\n",
            "Epoch [60/100], Loss: 0.0659\n",
            "Epoch [61/100], Loss: 0.0699\n",
            "Epoch [62/100], Loss: 0.0619\n",
            "Epoch [63/100], Loss: 0.0708\n",
            "Epoch [64/100], Loss: 0.0711\n",
            "Epoch [65/100], Loss: 0.0700\n"
          ]
        }
      ],
      "source": [
        "# Initialize Model\n",
        "# There's something wrong in here that involves the loss function\n",
        "\n",
        "vae = VariationalAutoencoder(latent_dim=latent_dim).to(device)\n",
        "criterion = vae_loss\n",
        "optimizer = optim.Adam(vae.parameters(), lr=0.001)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  for images, _ in dataloader:\n",
        "    images = images.view(images.size(0), -1).to(device)  # Flatten images\n",
        "    decoded_images, mu, logvar = vae(images)\n",
        "    loss = criterion(decoded_images, images, mu, logvar)  # Compare reconstructed and original\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZgL3Kt-knmXI"
      },
      "id": "ZgL3Kt-knmXI",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}